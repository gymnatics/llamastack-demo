# LlamaStack MCP Demo

A demonstration of LlamaStack orchestrating AI agents with Model Context Protocol (MCP) tools. This repo includes a Weather MCP Server, sample MongoDB data, and a Streamlit-based Demo UI.

![Architecture](https://img.shields.io/badge/LlamaStack-MCP-blue) ![OpenShift](https://img.shields.io/badge/OpenShift-Ready-red) ![License](https://img.shields.io/badge/License-Apache%202.0-green)

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚â”€â”€â”€â”€â–¶â”‚  Demo UI    â”‚â”€â”€â”€â”€â–¶â”‚ LlamaStack  â”‚â”€â”€â”€â”€â–¶â”‚     LLM     â”‚
â”‚  (Browser)  â”‚     â”‚ (Streamlit) â”‚     â”‚(Orchestrator)â”‚    â”‚   (vLLM)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚ Weather MCP â”‚â”€â”€â”€â”€â–¶â”‚   MongoDB   â”‚
                                        â”‚   Server    â”‚     â”‚  (Weather)  â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ What's Included

- ğŸ¨ **Demo UI** - Streamlit chatbot with real-time tool visualization
- ğŸŒ¤ï¸ **Weather MCP Server** - Sample MCP server with 5 weather tools
- ğŸ—„ï¸ **MongoDB** - Database with 14 global weather stations (48 hours of data each)

> **Note:** This repo deploys the demo components. You need an existing LlamaStack deployment.
> For full LlamaStack deployment with multi-provider support (vLLM, Azure, OpenAI, Ollama, Bedrock),
> use the [rhoai-toolkit.sh](https://github.com/gymnatics/openshift-installation).

---

## ğŸš€ Quick Start

### Prerequisites
- OpenShift cluster with RHOAI
- LlamaStack already deployed
- `oc` CLI installed and logged in

### One-Command Deploy

```bash
git clone https://github.com/gymnatics/llamastack-demo.git
cd llamastack-demo
./deploy.sh
```

The script offers 3 options:
1. **Complete Demo Stack** - UI + MCP + MongoDB (connects to existing LlamaStack)
2. **MCP + MongoDB only** - Just the backend
3. **UI only** - Just the frontend

---

## ğŸ“‹ Deployment Options

### Option 1: Complete Demo Stack
Deploys everything needed to demo MCP with your existing LlamaStack:
- Weather MCP Server
- MongoDB with sample data
- Demo UI

You'll be prompted for your LlamaStack URL and Model ID.

### Option 2: MCP + MongoDB Only
Just the backend components. Use this if you want to integrate with your own frontend or test MCP directly.

### Option 3: UI Only
Just the Streamlit demo. Use this if you already have an MCP server running.

---

## ğŸ”— Register MCP with LlamaStack

After deploying the Weather MCP Server, you need to register it with your LlamaStack:

Add to your LlamaStack config under `tool_groups`:

```yaml
- toolgroup_id: mcp::weather-data
  provider_id: model-context-protocol
  mcp_endpoint:
    uri: http://weather-mcp-server.YOUR_NAMESPACE.svc.cluster.local:8000/mcp
```

Then restart LlamaStack to load the new tools.

---

## ğŸ“ Project Structure

```
llamastack-demo/
â”œâ”€â”€ deploy.sh               # Deployment script
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ app.py                  # Demo UI (Streamlit)
â”œâ”€â”€ Dockerfile              # Demo UI container
â”œâ”€â”€ deployment.yaml         # Demo UI manifests
â”œâ”€â”€ buildconfig.yaml        # Demo UI build config
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ mcp/                    # Weather MCP Server
    â”œâ”€â”€ http_app.py         # MCP server application
    â”œâ”€â”€ Dockerfile          # MCP container
    â”œâ”€â”€ deployment.yaml     # MCP manifests
    â”œâ”€â”€ buildconfig.yaml    # MCP build config
    â”œâ”€â”€ mongodb-deployment.yaml
    â”œâ”€â”€ init-data-job.yaml
    â””â”€â”€ README.md
```

---

## ğŸŒ Included Weather Stations

| Code | City | Country |
|------|------|---------|
| VIDP | New Delhi | India |
| VABB | Mumbai | India |
| VOBL | Bangalore | India |
| VOMM | Chennai | India |
| VECC | Kolkata | India |
| WSSS | Singapore | Singapore |
| VHHH | Hong Kong | China |
| RJTT | Tokyo | Japan |
| EGLL | London | UK |
| LFPG | Paris | France |
| KJFK | New York | USA |
| KLAX | Los Angeles | USA |
| OMDB | Dubai | UAE |
| YSSY | Sydney | Australia |

---

## ğŸ”§ Weather MCP Tools

| Tool | Description |
|------|-------------|
| `search_weather` | Search observations with filters |
| `get_current_weather` | Get latest observation for a station |
| `list_stations` | List all available weather stations |
| `get_statistics` | Get database statistics |
| `health_check` | Check server and database health |

### Sample Queries
- "What's the weather in Delhi?"
- "Find airports with temperature above 30Â°C"
- "Which stations have fog right now?"
- "Compare weather in London and New York"

---

## ğŸ› ï¸ Full LlamaStack Deployment

Need to deploy LlamaStack from scratch with provider selection?

Use the **rhoai-toolkit.sh** from the main repository:

```bash
git clone https://github.com/gymnatics/openshift-installation.git
cd openshift-installation
./rhoai-toolkit.sh
# Choose: RHOAI Management â†’ Deploy LlamaStack Demo â†’ Deploy Everything with LlamaStack
```

This gives you:
- LlamaStack deployment with provider selection (vLLM, Azure, OpenAI, Ollama, Bedrock)
- Automatic MCP registration
- Complete end-to-end demo

---

## âš™ï¸ Customization

### Different Namespace
The script handles namespace substitution automatically.

### Custom Branding
Update `deployment.yaml` ConfigMap:
```yaml
data:
  APP_TITLE: "Your Company AI Assistant"
  APP_SUBTITLE: "Powered by LlamaStack"
  MCP_SERVER_NAME: "Your Data API"
```

### Your Own Data
1. Modify `mcp/init-data-job.yaml` with your data
2. Update `mcp/http_app.py` with your tools
3. Rebuild: `oc start-build weather-mcp-server --from-dir=mcp --follow`

---

## ğŸ“ License

Apache License 2.0

---

## ğŸ‘¤ Author

Danny Yeo

---

## ğŸ“– Blog Guide

For a comprehensive technical guide with troubleshooting and lessons learned, see:

**[BLOG-GUIDE.md](./BLOG-GUIDE.md)** - Building an AI Agent with LlamaStack and MCP on OpenShift AI

---

## ğŸ¤ Contributing

1. Fork this repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request
